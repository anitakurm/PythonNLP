library(tidyr)
data = read.csv("/Users/mariaa.madsen/Google Drive/NLP Anita and Maria/Data/relevant_features.csv")
names(data)[1] <- "Features"
data_long <- gather(data, Measure, Score, accuracy:f1_score, factor_key=TRUE)
data_long
p <- ggplot(data=data_long, aes(x=Features, y=Score, fill=Measure)) +
geom_bar(stat="identity", color="black", position=position_dodge())+
theme_minimal()
# Use custom colors
p + scale_fill_manual(values=c('#999999','#E69F00'))
# Use brewer color palettes
p + scale_fill_brewer(palette="Blues")
View(data_long)
data_long <- gather(data, Measure, Score, accuracy:f1_weigthed, factor_key=TRUE)
data_long
View(data_long)
data_long <- gather(data, Measure, Score, accuracy:f1_weighted, factor_key=TRUE)
data_long
p <- ggplot(data=data_long, aes(x=Features, y=Score, fill=Measure)) +
geom_bar(stat="identity", color="black", position=position_dodge())+
theme_minimal()
library(tidyr)
p <- ggplot(data=data_long, aes(x=Features, y=Score, fill=Measure)) +
geom_bar(stat="identity", color="black", position=position_dodge())+
theme_minimal()
library(ggplot2)
p <- ggplot(data=data_long, aes(x=Features, y=Score, fill=Measure)) +
geom_bar(stat="identity", color="black", position=position_dodge())+
theme_minimal()
p + scale_fill_manual(values=c('#999999','#E69F00'))
# Use brewer color palettes
p + scale_fill_brewer(palette="Blues")
library(tidyr)
library(ggplot2)
data = read.csv("/Users/mariaa.madsen/Google Drive/NLP Anita and Maria/Data/relevant_features.csv")
View(data)
names(data)[1] <- "Features"
data_long <- gather(data, Measure, Score, accuracy_balanced:f1_weighted, factor_key=TRUE)
data_long
# Change the colors manually
p <- ggplot(data=data_long, aes(x=Features, y=Score, fill=Measure)) +
geom_bar(stat="identity", color="black", position=position_dodge())+
theme_minimal()
# Use custom colors
p + scale_fill_manual(values=c('#999999','#E69F00'))
# Use brewer color palettes
p + scale_fill_brewer(palette="Blues")
?gsub
data_long$Features = gsub('score_', '',data_long$Features)
View(data_long)
# Change the colors manually
p <- ggplot(data=data_long, aes(x=Features, y=Score, fill=Measure)) +
geom_bar(stat="identity", color="black", position=position_dodge())+
theme_minimal()
# Use custom colors
p + scale_fill_manual(values=c('#999999','#E69F00'))
# Use brewer color palettes
p + scale_fill_brewer(palette="Blues")
library(pacman)
p_load(dplyr,stringr, tidytext, janeaustenr, tibble, rlang, reshape2, wordcloud, SnowballC, ggraph, igraph, widyr, purrr, broom, scales, tidyr, stringr, tidyverse, ggplot2, lubridate, readr)
df = read.csv("/Users/mariaa.madsen/Google Drive/Decision Making project/Data/likeagirl.csv", sep = ";", stringsAsFactor=FALSE)
names(df)[2] <- "rating"
View(data)
View(df)
library(pacman)
p_load(dplyr,stringr, tidytext, janeaustenr, tibble, rlang, reshape2, wordcloud, SnowballC, ggraph, igraph, widyr, purrr, broom, scales, tidyr, stringr, tidyverse, ggplot2, lubridate, readr)
df = read.csv("/Users/mariaa.madsen/Google Drive/Decision Making project/Data/likeagirl.csv", sep = ";", stringsAsFactor=FALSE)
View(df)
df = read.csv("/Users/mariaa.madsen/Google Drive/Decision Making project/Data/likeagirl.csv", sep = ",", stringsAsFactor=FALSE)
names(df)[2] <- "rating"
library(pacman)
p_load(dplyr,stringr, tidytext, janeaustenr, tibble, rlang, reshape2, wordcloud, SnowballC, ggraph, igraph, widyr, purrr, broom, scales, tidyr, stringr, tidyverse, ggplot2, lubridate, readr)
df = read.csv("/Users/mariaa.madsen/Google Drive/Decision Making project/Data/likeagirl.csv", sep = ",", stringsAsFactor=FALSE)
df %>%
count(Month = round_date(date, "month")) %>%
ggplot(aes(Month, n)) +
geom_line() +
ggtitle('The Number of Reviews Per Month')
# OBS: husk at tilføje %d i datasættet, for det bliver ikke gjort i python koden
df$date <- as.Date(df$date, format="%d-%m-%Y")
df %>%
count(Month = round_date(date, "month")) %>%
ggplot(aes(Month, n)) +
geom_line() +
ggtitle('The Number of Reviews Per Month')
df = read.csv("/Users/mariaa.madsen/Google Drive/Decision Making project/Data/likeagirl.csv", sep = ",", stringsAsFactor=FALSE)
# OBS: husk at tilføje %d i datasættet, for det bliver ikke gjort i python koden
df$date <- as.Date(df$date, format="%Y-%m-%d")
df %>%
count(Month = round_date(date, "month")) %>%
ggplot(aes(Month, n)) +
geom_line() +
ggtitle('The Number of Reviews Per Month')
df <- tibble::rowid_to_column(df, "ID")
review_words <- df %>%
distinct(review, .keep_all = TRUE) %>%
unnest_tokens(word, review, drop = FALSE) %>%
distinct(ID, word, .keep_all = TRUE) %>%
anti_join(stop_words, by = "word") %>%
filter(str_detect(word, "[^\\d]")) %>%
group_by(word) %>%
mutate(word_total = n()) %>%
ungroup()
names(df)[8] <- "review"
df %>%
count(Month = round_date(date, "month")) %>%
ggplot(aes(Month, n)) +
geom_line() +
ggtitle('The Number of Reviews Per Month')
df <- tibble::rowid_to_column(df, "ID")
review_words <- df %>%
distinct(review, .keep_all = TRUE) %>%
unnest_tokens(word, review, drop = FALSE) %>%
distinct(ID, word, .keep_all = TRUE) %>%
anti_join(stop_words, by = "word") %>%
filter(str_detect(word, "[^\\d]")) %>%
group_by(word) %>%
mutate(word_total = n()) %>%
ungroup()
review_words <- df %>%
distinct(review, .keep_all = TRUE) %>%
unnest_tokens(word, review, drop = FALSE) %>%
distinct(ID, word, .keep_all = TRUE) %>%
anti_join(stop_words, by = "word") %>%
filter(str_detect(word, "[^\\d]")) %>%
group_by(word) %>%
mutate(word_total = n()) %>%
ungroup()
review_words <- df %>%
distinct(review, .keep_all = TRUE) %>%
unnest_tokens(word, review, drop = FALSE) %>%
distinct(ID, word, .keep_all = TRUE) %>%
anti_join(stop_words, by = "word") %>%
filter(str_detect(word, "[^\\d]")) %>%
group_by(word) %>%
mutate(word_total = n()) %>%
ungroup()
word_counts <- review_words %>%
count(word, sort = TRUE)
word_counts %>%
head(25) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col(fill = "lightblue") +
scale_y_continuous(labels = comma_format()) +
coord_flip() +
labs(title = "Most common words in review text",
subtitle = "Among 2,455 reviews; stop words removed",
y = "# of uses")
word_counts %>%
head(25) %>%
mutate(word = wordStem(word)) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col(fill = "lightblue") +
scale_y_continuous(labels = comma_format()) +
coord_flip() +
labs(title = "Most common words in review text",
subtitle = "Among 2,455 reviews; stop words removed and stemmed",
y = "# of uses")
library(wordcloud)
review_words %>%
count(word) %>%
with(wordcloud(word, n, max.words = 100))
library(pacman)
p_load(dplyr,stringr, tidytext, janeaustenr, tibble, rlang, reshape2, wordcloud, SnowballC, ggraph, igraph, widyr, purrr, broom, scales, tidyr, stringr, tidyverse, ggplot2, lubridate, readr)
df = read.csv("/Users/mariaa.madsen/Google Drive/Decision Making project/Data/likeagirl_cleaned_rstudio.csv", sep = ",", stringsAsFactor=FALSE)
# OBS: husk at tilføje %d i datasættet, for det bliver ikke gjort i python koden
df$date <- as.Date(df$date, format="%Y-%m-%d")
library(pacman)
p_load(dplyr,stringr, tidytext, janeaustenr, tibble, rlang, reshape2, wordcloud, SnowballC, ggraph, igraph, widyr, purrr, broom, scales, tidyr, stringr, tidyverse, ggplot2, lubridate, readr)
df = read.csv("/Users/mariaa.madsen/Google Drive/Decision Making project/Data/likeagirl_cleaned_rstudio.csv", sep = ",", stringsAsFactor=FALSE)
df = read.csv("/Users/mariaa.madsen/Google Drive/Decision Making project/Data/likeagirl_cleaned.csv", sep = ",", stringsAsFactor=FALSE)
library(pacman)
p_load(dplyr,stringr, tidytext, janeaustenr, tibble, rlang, reshape2, wordcloud, SnowballC, ggraph, igraph, widyr, purrr, broom, scales, tidyr, stringr, tidyverse, ggplot2, lubridate, readr)
df = read.csv("/Users/mariaa.madsen/Google Drive/Decision Making project/Data/likeagirl_cleaned.csv", sep = ",", stringsAsFactor=FALSE)
library(pacman)
p_load(dplyr,stringr, tidytext, janeaustenr, tibble, rlang, reshape2, wordcloud, SnowballC, ggraph, igraph, widyr, purrr, broom, scales, tidyr, stringr, tidyverse, ggplot2, lubridate, readr)
df = read.csv("/Users/mariaa.madsen/Google Drive/Decision Making project/Data/likeagirl_cleaned.csv", sep = ",", stringsAsFactor=FALSE)
# OBS: husk at tilføje %d i datasættet, for det bliver ikke gjort i python koden
df$date <- as.Date(df$date, format="%Y-%m-%d")
names(df)[2] <- "review"
df %>%
count(Month = round_date(date, "month")) %>%
ggplot(aes(Month, n)) +
geom_line() +
ggtitle('The Number of tweets Per Month')
df <- tibble::rowid_to_column(df, "ID")
review_words <- df %>%
distinct(review, .keep_all = TRUE) %>%
unnest_tokens(word, review, drop = FALSE) %>%
distinct(ID, word, .keep_all = TRUE) %>%
anti_join(stop_words, by = "word") %>%
filter(str_detect(word, "[^\\d]")) %>%
group_by(word) %>%
mutate(word_total = n()) %>%
ungroup()
word_counts <- review_words %>%
count(word, sort = TRUE)
word_counts %>%
head(25) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col(fill = "lightblue") +
scale_y_continuous(labels = comma_format()) +
coord_flip() +
labs(title = "Most common words in review text",
subtitle = "Among 2,455 reviews; stop words removed",
y = "# of uses")
word_counts %>%
head(25) %>%
mutate(word = wordStem(word)) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col(fill = "lightblue") +
scale_y_continuous(labels = comma_format()) +
coord_flip() +
labs(title = "Most common words in review text",
subtitle = "Among 2,455 reviews; stop words removed and stemmed",
y = "# of uses")
library(wordcloud)
review_words %>%
count(word) %>%
with(wordcloud(word, n, max.words = 100))
review_bigrams <- df %>%
unnest_tokens(bigram, review, token = "ngrams", n = 2)
bigrams_separated <- review_bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
bigrams_filtered <- bigrams_separated %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
bigram_counts <- bigrams_filtered %>%
count(word1, word2, sort = TRUE)
bigrams_united <- bigrams_filtered %>%
unite(bigram, word1, word2, sep = " ")
bigrams_united %>%
count(bigram, sort = TRUE)
# filter for only relatively common combinations
bigram_graph <- bigram_counts %>%
filter(n > 20) %>%
graph_from_data_frame()
bigram_graph
library(ggraph)
ggraph(bigram_graph, layout = "fr") +
geom_edge_link() +
geom_node_point() +
geom_node_text(aes(label = name), vjust = 1, hjust = 1)
a <- grid::arrow(type = "closed", length = unit(.15, "inches"))
ggraph(bigram_graph, layout = "fr") +
geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
arrow = a, end_cap = circle(.07, 'inches')) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
theme_void()
review_subject <- df %>%
unnest_tokens(word, review) %>%
anti_join(stop_words)
my_stopwords <- data_frame(word = c(as.character(1:10)))
review_subject <- review_subject %>%
anti_join(my_stopwords)
title_word_pairs <- review_subject %>%
pairwise_count(word, ID, sort = TRUE, upper = FALSE)
set.seed(1234)
title_word_pairs %>%
filter(n >= 1000) %>%
graph_from_data_frame() %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "cyan4") +
geom_node_point(size = 5) +
geom_node_text(aes(label = name), repel = TRUE,
point.padding = unit(0.2, "lines")) +
ggtitle('Word network in TripAdvisor reviews') +
theme_void()
# Trigrams
review_trigrams <- df %>%
unnest_tokens(trigram, review, token = "ngrams", n = 3)
trigrams_separated <- review_trigrams %>%
separate(trigram, c("word1", "word2", "word3"), sep = " ")
trigrams_filtered <- trigrams_separated %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
filter(!word3 %in% stop_words$word)
trigram_counts <- trigrams_filtered %>%
count(word1, word2, word3, sort = TRUE)
trigrams_united <- trigrams_filtered %>%
unite(trigram, word1, word2, word3, sep = " ")
trigrams_united %>%
count(trigram, sort = TRUE)
reviews_per_month <- df %>%
group_by(df$date) %>%
summarize(month_total = n())
names(reviews_per_month)[1] <- "month"
TRUEword_month_counts <- review_words %>%
filter(word_total >= 1000) %>%
count(word, month) %>%
complete(word, month, fill = list(n = 0)) %>%
inner_join(reviews_per_month, by = "month") %>%
mutate(percent = n / month_total) %>%
mutate(year = year(month) + yday(month) / 365)
mod <- ~ glm(cbind(n, month_total - n) ~ year, ., family = "binomial")
slopes <- word_month_counts %>%
nest(-word) %>%
mutate(model = map(data, mod)) %>%
unnest(map(model, tidy)) %>%
filter(term == "year") %>%
arrange(desc(estimate))
slopes %>%
head(9) %>%
inner_join(word_month_counts, by = "word") %>%
mutate(word = reorder(word, -estimate)) %>%
ggplot(aes(month, n / month_total, color = word)) +
geom_line(show.legend = FALSE) +
scale_y_continuous(labels = percent_format()) +
facet_wrap(~ word, scales = "free_y") +
expand_limits(y = 0) +
labs(x = "Year",
y = "Percentage of reviews containing this word",
title = "9 fastest growing words in TripAdvisor reviews",
subtitle = "Judged by growth rate over 15 years")
reviews <- df %>%
filter(!is.na(review)) %>%
select(ID, review) %>%
group_by(row_number()) %>%
ungroup()
tidy_reviews <- reviews %>%
unnest_tokens(word, review)
tidy_reviews <- tidy_reviews %>%
anti_join(stop_words)
bing_word_counts <- tidy_reviews %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
bing_word_counts %>%
group_by(sentiment) %>%
top_n(10) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free") +
labs(y = "Contribution to sentiment", x = NULL) +
coord_flip() +
ggtitle('Words that contribute to positive and negative sentiment in the reviews')
library(reshape2)
bing <- get_sentiments("bing")
review_words %>%
inner_join(bing) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("#F8766D", "#00BFC4"),
max.words = 100)
review_words %>%
inner_join(bing) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("#000000", "#000000"),
max.words = 100)
review_words %>%
inner_join(bing) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("#F8766D", "#00BFC4"),
max.words = 500)
library(tidytext)
contributions <- tidy_reviews %>%
inner_join(get_sentiments("afinn"), by = "word") %>%
group_by(word) %>%
summarize(occurences = n(),
contribution = sum(score))
contributions %>%
top_n(25, abs(contribution)) %>%
mutate(word = reorder(word, contribution)) %>%
ggplot(aes(word, contribution, fill = contribution > 0)) +
ggtitle('Words with the greatest contributions to positive/negative
sentiment in reviews') +
geom_col(show.legend = FALSE) +
coord_flip()
# We want to see how often words are preceded by a word like “not”.
bigrams_separated %>%
filter(word1 == "not") %>%
count(word1, word2, sort = TRUE)
# with trigrams:
trigrams_separated %>%
filter(word1 == "not") %>%
count(word1, word2, word3, sort = TRUE)
### Virker ikke ###
AFINN <- get_sentiments("afinn")
not_words <- bigrams_separated %>%
filter(word1 == "not") %>%
inner_join(AFINN, by = c(word2 = "word")) %>%
count(word2, score, sort = TRUE) %>%
ungroup()
not_words
